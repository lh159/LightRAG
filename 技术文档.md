# LightRAGæ ‡ç­¾ä½“ç³»æ¼”ç¤ºDemoæ­å»ºæŒ‡å—

## ğŸ¯ é¡¹ç›®æ¦‚è¿°

åŸºäºLightRAGæŠ€æœ¯æ„å»ºæƒ…æ„Ÿé™ªä¼´åŠ©æ‰‹ï¼Œé›†æˆæ™ºèƒ½æ ‡ç­¾ä½“ç³»ï¼Œå®ç°ä¸ªæ€§åŒ–ç”¨æˆ·ç”»åƒå’Œæƒ…æ„Ÿå›åº”ã€‚

**æ ¸å¿ƒç‰¹æ€§**ï¼š
- è½»é‡åŒ–çŸ¥è¯†å›¾è°±å­˜å‚¨
- å¤šç”¨æˆ·éš”ç¦»æ ‡ç­¾ç®¡ç†  
- å®æ—¶æ ‡ç­¾æå–ä¸æƒé‡æ›´æ–°
- ä¸ªæ€§åŒ–æƒ…æ„Ÿé™ªä¼´å›åº”

---

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„è®¾è®¡

```
LightRAG-TagSystem-Demo/
â”œâ”€â”€ app/                        # ä¸»åº”ç”¨ç›®å½•
â”‚   â”œâ”€â”€ core/                   # æ ¸å¿ƒæ¨¡å—
â”‚   â”‚   â”œâ”€â”€ lightrag_engine.py  # LightRAGå¼•æ“
â”‚   â”‚   â”œâ”€â”€ tag_extractor.py    # æ ‡ç­¾æå–å™¨
â”‚   â”‚   â”œâ”€â”€ tag_manager.py      # æ ‡ç­¾ç®¡ç†å™¨
â”‚   â”‚   â””â”€â”€ response_generator.py # å›åº”ç”Ÿæˆå™¨
â”‚   â”œâ”€â”€ models/                 # æ•°æ®æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ user_model.py       # ç”¨æˆ·æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ tag_model.py        # æ ‡ç­¾æ¨¡å‹
â”‚   â”‚   â””â”€â”€ knowledge_model.py  # çŸ¥è¯†æ¨¡å‹
â”‚   â”œâ”€â”€ api/                    # APIæ¥å£
â”‚   â”‚   â”œâ”€â”€ chat_api.py         # èŠå¤©æ¥å£
â”‚   â”‚   â”œâ”€â”€ tag_api.py          # æ ‡ç­¾ç®¡ç†æ¥å£
â”‚   â”‚   â””â”€â”€ user_api.py         # ç”¨æˆ·ç®¡ç†æ¥å£
â”‚   â””â”€â”€ utils/                  # å·¥å…·å‡½æ•°
â”‚       â”œâ”€â”€ file_manager.py     # æ–‡ä»¶ç®¡ç†
â”‚       â”œâ”€â”€ llm_client.py       # LLMå®¢æˆ·ç«¯
â”‚       â””â”€â”€ config.py           # é…ç½®ç®¡ç†
â”œâ”€â”€ user_data/                  # ç”¨æˆ·æ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ user_123/              # ç”¨æˆ·æ•°æ®æ–‡ä»¶å¤¹
â”‚   â”‚   â”œâ”€â”€ documents/         # ç”¨æˆ·æ–‡æ¡£
â”‚   â”‚   â”œâ”€â”€ knowledge_graph/   # çŸ¥è¯†å›¾è°±æ–‡ä»¶
â”‚   â”‚   â”œâ”€â”€ user_tags.json     # ç”¨æˆ·æ ‡ç­¾
â”‚   â”‚   â””â”€â”€ conversation_log.json # å¯¹è¯è®°å½•
â”‚   â””â”€â”€ global/                # å…¨å±€é…ç½®
â”‚       â”œâ”€â”€ tag_templates.json # æ ‡ç­¾æ¨¡æ¿
â”‚       â””â”€â”€ system_config.json # ç³»ç»Ÿé…ç½®
â”œâ”€â”€ web/                       # Webç•Œé¢
â”‚   â”œâ”€â”€ templates/             # HTMLæ¨¡æ¿
â”‚   â”œâ”€â”€ static/                # é™æ€èµ„æº
â”‚   â””â”€â”€ app.py                 # Flaskåº”ç”¨
â”œâ”€â”€ requirements.txt           # ä¾èµ–åŒ…
â”œâ”€â”€ config.yaml               # ä¸»é…ç½®æ–‡ä»¶
â””â”€â”€ run_demo.py              # å¯åŠ¨è„šæœ¬
```

---

## ğŸ“‹ ç¯å¢ƒæ­å»ºæ­¥éª¤

### ç¬¬ä¸€æ­¥ï¼šåŸºç¡€ç¯å¢ƒå‡†å¤‡

```bash
# 1. åˆ›å»ºé¡¹ç›®ç›®å½•
mkdir LightRAG-TagSystem-Demo
cd LightRAG-TagSystem-Demo

# 2. åˆ›å»ºPythonè™šæ‹Ÿç¯å¢ƒ
python -m venv lightrag_env
source lightrag_env/bin/activate  # Linux/Mac
# lightrag_env\Scripts\activate   # Windows

# 3. å®‰è£…ä¾èµ–åŒ…
pip install -r requirements.txt
```

### ç¬¬äºŒæ­¥ï¼šä¾èµ–åŒ…é…ç½®

```txt
# requirements.txt
lightrag==0.1.0
openai==1.3.0
chromadb==0.4.15
fastapi==0.104.1
uvicorn==0.24.0
pydantic==2.5.0
python-multipart==0.0.6
jinja2==3.1.2
aiofiles==23.2.1
sqlite3
pandas==2.1.3
numpy==1.24.3
networkx==3.2
flask==3.0.0
```

---

## ğŸ”§ æ ¸å¿ƒä»£ç å®ç°

### 1. LightRAGå¼•æ“é›†æˆ (app/core/lightrag_engine.py)

```python
import os
import json
from typing import Dict, List, Optional
from lightrag import LightRAG, QueryParam
from lightrag.llm import gpt_4o_mini_complete, gpt_4o_complete
from lightrag.embed import openai_embedding

class LightRAGEngine:
    def __init__(self, user_id: str):
        self.user_id = user_id
        self.user_data_path = f"user_data/{user_id}"
        self.ensure_user_directory()
        
        # åˆå§‹åŒ–LightRAGå®ä¾‹
        self.rag = LightRAG(
            working_dir=self.user_data_path,
            llm_model_func=gpt_4o_mini_complete,
            embedding_func=openai_embedding,
        )
        
    def ensure_user_directory(self):
        """ç¡®ä¿ç”¨æˆ·ç›®å½•å­˜åœ¨"""
        os.makedirs(self.user_data_path, exist_ok=True)
        os.makedirs(f"{self.user_data_path}/documents", exist_ok=True)
        os.makedirs(f"{self.user_data_path}/knowledge_graph", exist_ok=True)
        
    def insert_knowledge(self, text: str, metadata: Dict = None):
        """æ’å…¥çŸ¥è¯†åˆ°ç”¨æˆ·çŸ¥è¯†åº“"""
        try:
            # æ·»åŠ å…ƒæ•°æ®æ ‡è®°
            if metadata:
                text = f"[metadata: {json.dumps(metadata)}]\n{text}"
            
            self.rag.insert(text)
            return {"status": "success", "message": "çŸ¥è¯†æ’å…¥æˆåŠŸ"}
        except Exception as e:
            return {"status": "error", "message": f"æ’å…¥å¤±è´¥: {str(e)}"}
    
    def query_knowledge(self, query: str, mode: str = "hybrid") -> str:
        """æŸ¥è¯¢çŸ¥è¯†åº“"""
        try:
            # æ ¹æ®æŸ¥è¯¢æ¨¡å¼è®¾ç½®å‚æ•°
            if mode == "naive":
                param = QueryParam(mode="naive")
            elif mode == "local":
                param = QueryParam(mode="local")
            elif mode == "global":
                param = QueryParam(mode="global")
            else:
                param = QueryParam(mode="hybrid")
            
            response = self.rag.query(query, param=param)
            return response
        except Exception as e:
            return f"æŸ¥è¯¢é”™è¯¯: {str(e)}"
    
    def get_knowledge_graph(self):
        """è·å–çŸ¥è¯†å›¾è°±ç»“æ„"""
        try:
            graph_path = f"{self.user_data_path}/graph_chunk_entity_relation.graphml"
            if os.path.exists(graph_path):
                # è¿™é‡Œå¯ä»¥è§£æGraphMLæ–‡ä»¶è¿”å›å›¾ç»“æ„
                return {"status": "success", "graph_exists": True}
            else:
                return {"status": "success", "graph_exists": False}
        except Exception as e:
            return {"status": "error", "message": str(e)}
```

### 2. æ ‡ç­¾æå–å™¨ (app/core/tag_extractor.py)

```python
import json
import re
from datetime import datetime
from typing import Dict, List
from dataclasses import dataclass
from app.utils.llm_client import LLMClient

@dataclass
class TagInfo:
    name: str
    confidence: float
    evidence: str
    category: str

class TagExtractor:
    def __init__(self, user_id: str):
        self.user_id = user_id
        self.llm_client = LLMClient()
        self.tag_categories = {
            "emotional_traits": "æƒ…æ„Ÿç‰¹å¾",
            "interest_preferences": "å…´è¶£åå¥½", 
            "interaction_habits": "äº’åŠ¨ä¹ æƒ¯",
            "value_principles": "ä»·å€¼è§‚"
        }
        
    def extract_tags_from_text(self, text: str, context: Dict = None) -> Dict[str, List[TagInfo]]:
        """ä»æ–‡æœ¬ä¸­æå–æ ‡ç­¾"""
        
        # æ„å»ºæå–prompt
        extraction_prompt = self._build_extraction_prompt(text, context)
        
        # è°ƒç”¨LLMæå–
        try:
            llm_response = self.llm_client.complete(
                extraction_prompt, 
                max_tokens=300,
                temperature=0.3
            )
            
            # è§£æLLMå“åº”
            extracted_tags = self._parse_llm_response(llm_response, text)
            
            # æ·»åŠ è¡Œä¸ºæ¨¡å¼åˆ†æ
            behavior_tags = self._analyze_behavior_patterns(text)
            
            # èåˆç»“æœ
            final_tags = self._merge_tag_results(extracted_tags, behavior_tags)
            
            return final_tags
            
        except Exception as e:
            print(f"æ ‡ç­¾æå–é”™è¯¯: {e}")
            return {}
    
    def _build_extraction_prompt(self, text: str, context: Dict = None) -> str:
        """æ„å»ºæ ‡ç­¾æå–çš„prompt"""
        context_info = ""
        if context:
            context_info = f"å¯¹è¯ä¸Šä¸‹æ–‡: {context.get('previous_messages', '')}\n"
        
        prompt = f"""
        ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¿ƒç†åˆ†æå¸ˆï¼Œè¯·åˆ†æä»¥ä¸‹ç”¨æˆ·æ–‡æœ¬å¹¶æå–æ ‡ç­¾ã€‚
        
        {context_info}
        ç”¨æˆ·æ–‡æœ¬: "{text}"
        
        è¯·ä»ä»¥ä¸‹4ä¸ªç»´åº¦æå–æ ‡ç­¾ï¼ˆæ¯ä¸ªç»´åº¦æœ€å¤š3ä¸ªæ ‡ç­¾ï¼‰ï¼š
        1. æƒ…æ„Ÿç‰¹å¾ - ç”¨æˆ·çš„æƒ…ç»ªå€¾å‘å’Œå¿ƒç†ç‰¹ç‚¹
        2. å…´è¶£åå¥½ - ç”¨æˆ·æ„Ÿå…´è¶£æˆ–åæ„Ÿçš„è¯é¢˜å†…å®¹
        3. äº’åŠ¨ä¹ æƒ¯ - ç”¨æˆ·çš„äº¤æµé£æ ¼å’Œå›åº”åå¥½
        4. ä»·å€¼è§‚ - ç”¨æˆ·çš„åŸåˆ™ç«‹åœºå’Œåº•çº¿ç¦å¿Œ
        
        è¾“å‡ºJSONæ ¼å¼ï¼š
        {{
            "æƒ…æ„Ÿç‰¹å¾": [
                {{"tag": "æ ‡ç­¾å", "confidence": 0.8, "evidence": "æ”¯æ’‘è¯æ®"}}
            ],
            "å…´è¶£åå¥½": [...],
            "äº’åŠ¨ä¹ æƒ¯": [...], 
            "ä»·å€¼è§‚": [...]
        }}
        
        æ³¨æ„ï¼š
        - confidenceèŒƒå›´0.1-1.0ï¼Œè¡¨ç¤ºè¯¥æ ‡ç­¾çš„ç¡®ä¿¡åº¦
        - evidenceæ˜¯ä»åŸæ–‡ä¸­æå–çš„æ”¯æ’‘è¯¥æ ‡ç­¾çš„å…·ä½“å¥å­
        - å¦‚æœæŸä¸ªç»´åº¦æ²¡æœ‰æ˜æ˜¾ç‰¹å¾ï¼Œè¿”å›ç©ºæ•°ç»„
        """
        
        return prompt
    
    def _parse_llm_response(self, response: str, original_text: str) -> Dict[str, List[TagInfo]]:
        """è§£æLLMè¿”å›çš„æ ‡ç­¾"""
        try:
            # æå–JSONéƒ¨åˆ†
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if not json_match:
                return {}
            
            json_str = json_match.group(0)
            tag_data = json.loads(json_str)
            
            parsed_tags = {}
            for category_cn, tags in tag_data.items():
                # è½¬æ¢ä¸­æ–‡åˆ†ç±»åä¸ºè‹±æ–‡key
                category_en = self._get_category_key(category_cn)
                if category_en:
                    parsed_tags[category_en] = []
                    for tag_info in tags:
                        tag = TagInfo(
                            name=tag_info.get("tag", ""),
                            confidence=tag_info.get("confidence", 0.5),
                            evidence=tag_info.get("evidence", ""),
                            category=category_en
                        )
                        parsed_tags[category_en].append(tag)
            
            return parsed_tags
            
        except Exception as e:
            print(f"è§£æLLMå“åº”é”™è¯¯: {e}")
            return {}
    
    def _get_category_key(self, category_cn: str) -> str:
        """æ ¹æ®ä¸­æ–‡åˆ†ç±»åè·å–è‹±æ–‡key"""
        for key, value in self.tag_categories.items():
            if value == category_cn:
                return key
        return ""
    
    def _analyze_behavior_patterns(self, text: str) -> Dict[str, List[TagInfo]]:
        """åŸºäºè§„åˆ™çš„è¡Œä¸ºæ¨¡å¼åˆ†æ"""
        behavior_tags = {}
        
        # æ–‡æœ¬é•¿åº¦åˆ†æ
        if len(text) > 100:
            behavior_tags["interaction_habits"] = [
                TagInfo("åå¥½è¯¦ç»†è¡¨è¾¾", 0.6, f"æ–‡æœ¬é•¿åº¦{len(text)}å­—ç¬¦", "interaction_habits")
            ]
        elif len(text) < 30:
            behavior_tags["interaction_habits"] = [
                TagInfo("åå¥½ç®€çŸ­äº¤æµ", 0.6, f"æ–‡æœ¬é•¿åº¦{len(text)}å­—ç¬¦", "interaction_habits")
            ]
        
        # æƒ…æ„Ÿè¯æ£€æµ‹
        positive_words = ["å¼€å¿ƒ", "é«˜å…´", "å¿«ä¹", "æ»¡æ„", "ä¸é”™", "å¥½çš„"]
        negative_words = ["éš¾è¿‡", "æ²®ä¸§", "å¤±æœ›", "ç³Ÿç³•", "ç—›è‹¦", "çƒ¦èº"]
        
        positive_count = sum(1 for word in positive_words if word in text)
        negative_count = sum(1 for word in negative_words if word in text)
        
        if positive_count > negative_count and positive_count > 0:
            if "emotional_traits" not in behavior_tags:
                behavior_tags["emotional_traits"] = []
            behavior_tags["emotional_traits"].append(
                TagInfo("æƒ…ç»ªåå‘ç§¯æ", 0.7, f"ç§¯æè¯æ±‡{positive_count}ä¸ª", "emotional_traits")
            )
        elif negative_count > positive_count and negative_count > 0:
            if "emotional_traits" not in behavior_tags:
                behavior_tags["emotional_traits"] = []
            behavior_tags["emotional_traits"].append(
                TagInfo("æƒ…ç»ªåå‘æ¶ˆæ", 0.7, f"æ¶ˆæè¯æ±‡{negative_count}ä¸ª", "emotional_traits")
            )
        
        return behavior_tags
    
    def _merge_tag_results(self, llm_tags: Dict, behavior_tags: Dict) -> Dict[str, List[TagInfo]]:
        """èåˆLLMæå–å’Œè¡Œä¸ºåˆ†æçš„ç»“æœ"""
        merged = llm_tags.copy()
        
        for category, tags in behavior_tags.items():
            if category not in merged:
                merged[category] = []
            
            # é¿å…é‡å¤æ ‡ç­¾
            existing_names = [tag.name for tag in merged[category]]
            for tag in tags:
                if tag.name not in existing_names:
                    merged[category].append(tag)
        
        return merged
```

### 3. æ ‡ç­¾ç®¡ç†å™¨ (app/core/tag_manager.py)

```python
import json
import os
from datetime import datetime, timedelta
from typing import Dict, List, Optional
from app.core.tag_extractor import TagInfo

class TagManager:
    def __init__(self, user_id: str):
        self.user_id = user_id
        self.user_data_path = f"user_data/{user_id}"
        self.tags_file = f"{self.user_data_path}/user_tags.json"
        self.timeline_file = f"{self.user_data_path}/tag_timeline.json"
        
        # ç¡®ä¿æ–‡ä»¶å­˜åœ¨
        self._ensure_tag_files()
        
    def _ensure_tag_files(self):
        """ç¡®ä¿æ ‡ç­¾æ–‡ä»¶å­˜åœ¨"""
        if not os.path.exists(self.tags_file):
            self._create_empty_tags_file()
        if not os.path.exists(self.timeline_file):
            self._create_empty_timeline_file()
    
    def _create_empty_tags_file(self):
        """åˆ›å»ºç©ºçš„æ ‡ç­¾æ–‡ä»¶"""
        empty_tags = {
            "user_id": self.user_id,
            "created_at": datetime.now().isoformat(),
            "last_updated": datetime.now().isoformat(),
            "tag_dimensions": {
                "emotional_traits": {
                    "dimension_name": "æƒ…æ„Ÿç‰¹å¾ç»´åº¦",
                    "active_tags": [],
                    "dominant_tag": None,
                    "dimension_weight": 0.0,
                    "stability_score": 0.0
                },
                "interest_preferences": {
                    "dimension_name": "å…´è¶£åå¥½ç»´åº¦", 
                    "active_tags": [],
                    "dominant_tag": None,
                    "dimension_weight": 0.0,
                    "stability_score": 0.0
                },
                "interaction_habits": {
                    "dimension_name": "äº’åŠ¨ä¹ æƒ¯ç»´åº¦",
                    "active_tags": [],
                    "dominant_tag": None,
                    "dimension_weight": 0.0,
                    "stability_score": 0.0
                },
                "value_principles": {
                    "dimension_name": "ä»·å€¼è§‚ç»´åº¦",
                    "active_tags": [],
                    "dominant_tag": None,
                    "dimension_weight": 0.0,
                    "stability_score": 0.0
                }
            },
            "computed_metrics": {
                "emotional_health_index": 0.5,
                "interest_concentration": 0.0,
                "interaction_dependency": 0.0,
                "overall_profile_maturity": 0.0
            }
        }
        
        with open(self.tags_file, 'w', encoding='utf-8') as f:
            json.dump(empty_tags, f, ensure_ascii=False, indent=2)
    
    def _create_empty_timeline_file(self):
        """åˆ›å»ºç©ºçš„æ—¶é—´è½´æ–‡ä»¶"""
        empty_timeline = {
            "user_id": self.user_id,
            "created_at": datetime.now().isoformat(),
            "tag_events": []
        }
        
        with open(self.timeline_file, 'w', encoding='utf-8') as f:
            json.dump(empty_timeline, f, ensure_ascii=False, indent=2)
    
    def update_tags(self, extracted_tags: Dict[str, List[TagInfo]]) -> Dict:
        """æ›´æ–°ç”¨æˆ·æ ‡ç­¾"""
        # åŠ è½½å½“å‰æ ‡ç­¾
        current_tags = self._load_current_tags()
        
        # æ›´æ–°å„ç»´åº¦æ ‡ç­¾
        for dimension, new_tags in extracted_tags.items():
            if dimension in current_tags["tag_dimensions"]:
                self._update_dimension_tags(
                    current_tags["tag_dimensions"][dimension], 
                    new_tags
                )
        
        # é‡æ–°è®¡ç®—æƒé‡å’ŒæŒ‡æ ‡
        self._recalculate_weights_and_metrics(current_tags)
        
        # æ›´æ–°æ—¶é—´æˆ³
        current_tags["last_updated"] = datetime.now().isoformat()
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        self._save_tags(current_tags)
        
        # è®°å½•åˆ°æ—¶é—´è½´
        self._record_tag_timeline(extracted_tags)
        
        return current_tags
    
    def _load_current_tags(self) -> Dict:
        """åŠ è½½å½“å‰æ ‡ç­¾"""
        with open(self.tags_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def _update_dimension_tags(self, dimension_data: Dict, new_tags: List[TagInfo]):
        """æ›´æ–°å•ä¸ªç»´åº¦çš„æ ‡ç­¾"""
        active_tags = dimension_data["active_tags"]
        
        for new_tag in new_tags:
            # æŸ¥æ‰¾æ˜¯å¦å·²å­˜åœ¨ç›¸åŒæ ‡ç­¾
            existing_tag = None
            for tag in active_tags:
                if tag["tag_name"] == new_tag.name:
                    existing_tag = tag
                    break
            
            if existing_tag:
                # å¼ºåŒ–å·²æœ‰æ ‡ç­¾
                existing_tag["evidence_count"] += 1
                existing_tag["last_reinforced"] = datetime.now().isoformat()
                existing_tag["total_confidence"] += new_tag.confidence
                existing_tag["avg_confidence"] = existing_tag["total_confidence"] / existing_tag["evidence_count"]
                
                # æ·»åŠ æ–°è¯æ®
                if "evidences" not in existing_tag:
                    existing_tag["evidences"] = []
                existing_tag["evidences"].append({
                    "text": new_tag.evidence,
                    "timestamp": datetime.now().isoformat(),
                    "confidence": new_tag.confidence
                })
                
                # é™åˆ¶è¯æ®æ•°é‡ï¼ˆä¿ç•™æœ€è¿‘10æ¡ï¼‰
                if len(existing_tag["evidences"]) > 10:
                    existing_tag["evidences"] = existing_tag["evidences"][-10:]
            else:
                # æ·»åŠ æ–°æ ‡ç­¾
                new_tag_data = {
                    "tag_name": new_tag.name,
                    "first_detected": datetime.now().isoformat(),
                    "last_reinforced": datetime.now().isoformat(),
                    "evidence_count": 1,
                    "total_confidence": new_tag.confidence,
                    "avg_confidence": new_tag.confidence,
                    "decay_rate": 0.1,
                    "evidences": [{
                        "text": new_tag.evidence,
                        "timestamp": datetime.now().isoformat(),
                        "confidence": new_tag.confidence
                    }]
                }
                active_tags.append(new_tag_data)
        
        # åº”ç”¨æ—¶é—´è¡°å‡
        self._apply_time_decay(active_tags)
        
        # é™åˆ¶æ ‡ç­¾æ•°é‡ï¼ˆä¿ç•™æƒé‡æœ€é«˜çš„20ä¸ªï¼‰
        if len(active_tags) > 20:
            active_tags.sort(key=lambda x: x["avg_confidence"], reverse=True)
            dimension_data["active_tags"] = active_tags[:20]
    
    def _apply_time_decay(self, active_tags: List[Dict]):
        """åº”ç”¨æ—¶é—´è¡°å‡"""
        now = datetime.now()
        
        for tag in active_tags:
            last_reinforced = datetime.fromisoformat(tag["last_reinforced"])
            days_since_reinforced = (now - last_reinforced).days
            
            # è®¡ç®—è¡°å‡å› å­
            decay_factor = max(0.1, 1.0 - (days_since_reinforced * tag["decay_rate"] / 30))
            tag["current_weight"] = tag["avg_confidence"] * decay_factor
    
    def _recalculate_weights_and_metrics(self, tags_data: Dict):
        """é‡æ–°è®¡ç®—æƒé‡å’ŒæŒ‡æ ‡"""
        dimensions = tags_data["tag_dimensions"]
        
        for dimension_key, dimension_data in dimensions.items():
            active_tags = dimension_data["active_tags"]
            
            if active_tags:
                # æ‰¾åˆ°ä¸»å¯¼æ ‡ç­¾ï¼ˆæƒé‡æœ€é«˜ï¼‰
                dominant_tag = max(active_tags, key=lambda x: x.get("current_weight", 0))
                dimension_data["dominant_tag"] = dominant_tag["tag_name"]
                
                # è®¡ç®—ç»´åº¦æƒé‡
                dimension_data["dimension_weight"] = dominant_tag.get("current_weight", 0)
                
                # è®¡ç®—ç¨³å®šæ€§è¯„åˆ†ï¼ˆåŸºäºæ ‡ç­¾æ•°é‡å’Œå¹³å‡ç½®ä¿¡åº¦ï¼‰
                avg_confidence = sum(tag.get("avg_confidence", 0) for tag in active_tags) / len(active_tags)
                tag_count_factor = min(1.0, len(active_tags) / 10.0)
                dimension_data["stability_score"] = avg_confidence * tag_count_factor
            else:
                dimension_data["dominant_tag"] = None
                dimension_data["dimension_weight"] = 0.0
                dimension_data["stability_score"] = 0.0
        
        # è®¡ç®—ç»¼åˆæŒ‡æ ‡
        self._compute_overall_metrics(tags_data)
    
    def _compute_overall_metrics(self, tags_data: Dict):
        """è®¡ç®—ç»¼åˆæŒ‡æ ‡"""
        dimensions = tags_data["tag_dimensions"]
        metrics = tags_data["computed_metrics"]
        
        # æƒ…æ„Ÿå¥åº·æŒ‡æ•° (åŸºäºæƒ…æ„Ÿç‰¹å¾ç»´åº¦)
        emotional_dim = dimensions.get("emotional_traits", {})
        emotional_tags = emotional_dim.get("active_tags", [])
        
        positive_weight = 0
        negative_weight = 0
        for tag in emotional_tags:
            tag_name = tag["tag_name"]
            weight = tag.get("current_weight", 0)
            
            if any(word in tag_name for word in ["ä¹è§‚", "ç§¯æ", "å¼€æœ—", "è‡ªä¿¡"]):
                positive_weight += weight
            elif any(word in tag_name for word in ["ç„¦è™‘", "æ¶ˆæ", "æ‚²è§‚", "æ•æ„Ÿ"]):
                negative_weight += weight
        
        total_emotional_weight = positive_weight + negative_weight
        if total_emotional_weight > 0:
            metrics["emotional_health_index"] = (positive_weight - negative_weight * 0.5) / total_emotional_weight
        else:
            metrics["emotional_health_index"] = 0.5
        
        # å…´è¶£é›†ä¸­åº¦
        interest_dim = dimensions.get("interest_preferences", {})
        interest_tags = interest_dim.get("active_tags", [])
        
        if interest_tags:
            weights = [tag.get("current_weight", 0) for tag in interest_tags]
            sum_weights = sum(weights)
            sum_squares = sum(w**2 for w in weights)
            metrics["interest_concentration"] = sum_squares / (sum_weights**2) if sum_weights > 0 else 0
        else:
            metrics["interest_concentration"] = 0
        
        # äº’åŠ¨ä¾èµ–åº¦ï¼ˆåŸºäºäº’åŠ¨ä¹ æƒ¯æ ‡ç­¾ï¼‰
        interaction_dim = dimensions.get("interaction_habits", {})  
        interaction_tags = interaction_dim.get("active_tags", [])
        
        dependency_indicators = ["éœ€è¦å®‰æ…°", "å¯»æ±‚è®¤å¯", "ä¾èµ–ä»–äºº", "éœ€è¦å€¾å¬"]
        independence_indicators = ["ç‹¬ç«‹æ€è€ƒ", "è‡ªä¸»å†³ç­–", "åå¥½ç‹¬å¤„"]
        
        dependency_weight = 0
        independence_weight = 0
        
        for tag in interaction_tags:
            tag_name = tag["tag_name"]
            weight = tag.get("current_weight", 0)
            
            if any(indicator in tag_name for indicator in dependency_indicators):
                dependency_weight += weight
            elif any(indicator in tag_name for indicator in independence_indicators):
                independence_weight += weight
        
        total_interaction_weight = dependency_weight + independence_weight
        if total_interaction_weight > 0:
            metrics["interaction_dependency"] = dependency_weight / total_interaction_weight
        else:
            metrics["interaction_dependency"] = 0.5
        
        # æ•´ä½“ç”»åƒæˆç†Ÿåº¦
        total_dimensions = len(dimensions)
        active_dimensions = sum(1 for dim in dimensions.values() if dim["dimension_weight"] > 0.1)
        avg_stability = sum(dim["stability_score"] for dim in dimensions.values()) / total_dimensions
        
        metrics["overall_profile_maturity"] = (active_dimensions / total_dimensions) * avg_stability
    
    def _save_tags(self, tags_data: Dict):
        """ä¿å­˜æ ‡ç­¾æ•°æ®"""
        with open(self.tags_file, 'w', encoding='utf-8') as f:
            json.dump(tags_data, f, ensure_ascii=False, indent=2)
    
    def _record_tag_timeline(self, extracted_tags: Dict[str, List[TagInfo]]):
        """è®°å½•æ ‡ç­¾æ—¶é—´è½´"""
        timeline_data = self._load_timeline()
        
        event = {
            "timestamp": datetime.now().isoformat(),
            "event_type": "tag_extraction",
            "extracted_tags": {}
        }
        
        for dimension, tags in extracted_tags.items():
            event["extracted_tags"][dimension] = [
                {
                    "tag_name": tag.name,
                    "confidence": tag.confidence,
                    "evidence": tag.evidence
                }
                for tag in tags
            ]
        
        timeline_data["tag_events"].append(event)
        
        # é™åˆ¶æ—¶é—´è½´é•¿åº¦ï¼ˆä¿ç•™æœ€è¿‘100ä¸ªäº‹ä»¶ï¼‰
        if len(timeline_data["tag_events"]) > 100:
            timeline_data["tag_events"] = timeline_data["tag_events"][-100:]
        
        with open(self.timeline_file, 'w', encoding='utf-8') as f:
            json.dump(timeline_data, f, ensure_ascii=False, indent=2)
    
    def _load_timeline(self) -> Dict:
        """åŠ è½½æ—¶é—´è½´æ•°æ®"""
        with open(self.timeline_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def get_user_tags(self) -> Dict:
        """è·å–ç”¨æˆ·æ ‡ç­¾"""
        return self._load_current_tags()
    
    def get_dimension_weight(self, dimension: str) -> float:
        """è·å–ç»´åº¦æƒé‡"""
        tags_data = self._load_current_tags()
        return tags_data["tag_dimensions"].get(dimension, {}).get("dimension_weight", 0.0)
    
    def get_tag_timeline(self) -> Dict:
        """è·å–æ ‡ç­¾æ—¶é—´è½´"""
        return self._load_timeline()
```

### 4. ä¸ªæ€§åŒ–å›åº”ç”Ÿæˆå™¨ (app/core/response_generator.py)

```python
from typing import Dict, List
from app.core.lightrag_engine import LightRAGEngine
from app.core.tag_manager import TagManager
from app.utils.llm_client import LLMClient

class ResponseGenerator:
    def __init__(self, user_id: str):
        self.user_id = user_id
        self.lightrag = LightRAGEngine(user_id)
        self.tag_manager = TagManager(user_id)
        self.llm_client = LLMClient()
        
    def generate_response(self, user_query: str, context: Dict = None) -> Dict:
        """ç”Ÿæˆä¸ªæ€§åŒ–å›åº”"""
        
        # 1. è·å–ç”¨æˆ·æ ‡ç­¾
        user_tags = self.tag_manager.get_user_tags()
        
        # 2. åŸºäºæ ‡ç­¾ç”Ÿæˆæ£€ç´¢ç­–ç•¥
        search_strategy = self._generate_search_strategy(user_tags, user_query)
        
        # 3. ä½¿ç”¨LightRAGæ£€ç´¢ç›¸å…³çŸ¥è¯†
        relevant_knowledge = self.lightrag.query_knowledge(
            user_query, 
            mode=search_strategy.get("search_mode", "hybrid")
        )
        
        # 4. æ„å»ºä¸ªæ€§åŒ–å›åº”prompt
        personalized_prompt = self._build_response_prompt(
            user_query, 
            relevant_knowledge, 
            user_tags, 
            search_strategy,
            context
        )
        
        # 5. ç”Ÿæˆå›åº”
        response = self.llm_client.complete(
            personalized_prompt,
            max_tokens=500,
            temperature=0.7
        )
        
        # 6. åå¤„ç†å’Œå®‰å…¨æ£€æŸ¥
        final_response = self._post_process_response(response, search_strategy)
        
        return {
            "response": final_response,
            "search_strategy": search_strategy,
            "knowledge_used": relevant_knowledge[:200] + "..." if len(relevant_knowledge) > 200 else relevant_knowledge,
            "user_profile_snapshot": self._get_profile_snapshot(user_tags)
        }
    
    def _generate_search_strategy(self, user_tags: Dict, query: str) -> Dict:
        """åŸºäºç”¨æˆ·æ ‡ç­¾ç”Ÿæˆæ£€ç´¢ç­–ç•¥"""
        strategy = {
            "search_mode": "hybrid",
            "response_tone": "warm",
            "response_style": "balanced",
            "content_filters": [],
            "boost_topics": [],
            "avoid_topics": [],
            "emotional_adaptation": "neutral"
        }
        
        dimensions = user_tags.get("tag_dimensions", {})
        
        # åŸºäºæƒ…æ„Ÿç‰¹å¾è°ƒæ•´
        emotional_dim = dimensions.get("emotional_traits", {})
        if emotional_dim.get("dimension_weight", 0) > 0.5:
            dominant_emotional = emotional_dim.get("dominant_tag", "")
            
            if "æ•æ„Ÿ" in dominant_emotional or "ç„¦è™‘" in dominant_emotional:
                strategy["response_tone"] = "gentle"
                strategy["content_filters"].extend(["æ‰¹è¯„", "å¦å®š", "å¤±è´¥"])
                strategy["emotional_adaptation"] = "supportive"
            elif "ä¹è§‚" in dominant_emotional or "ç§¯æ" in dominant_emotional:
                strategy["response_tone"] = "upbeat"
                strategy["emotional_adaptation"] = "encouraging"
        
        # åŸºäºå…´è¶£åå¥½è°ƒæ•´
        interest_dim = dimensions.get("interest_preferences", {})
        interest_tags = interest_dim.get("active_tags", [])
        
        for tag in interest_tags:
            if tag.get("current_weight", 0) > 0.6:
                tag_name = tag["tag_name"]
                if "å® ç‰©" in tag_name:
                    strategy["boost_topics"].append("å® ç‰©")
                elif "éŸ³ä¹" in tag_name:
                    strategy["boost_topics"].append("éŸ³ä¹")
                elif "ç§‘æŠ€" in tag_name:
                    strategy["boost_topics"].append("ç§‘æŠ€")
                # æ·»åŠ åæ„Ÿè¯é¢˜åˆ°é¿å…åˆ—è¡¨
                elif "åæ„Ÿ" in tag_name or "è®¨åŒ" in tag_name:
                    avoid_topic = tag_name.replace("åæ„Ÿ", "").replace("è®¨åŒ", "")
                    strategy["avoid_topics"].append(avoid_topic)
        
        # åŸºäºäº’åŠ¨ä¹ æƒ¯è°ƒæ•´
        interaction_dim = dimensions.get("interaction_habits", {})
        interaction_tags = interaction_dim.get("active_tags", [])
        
        for tag in interaction_tags:
            if tag.get("current_weight", 0) > 0.6:
                tag_name = tag["tag_name"]
                if "ç®€çŸ­" in tag_name:
                    strategy["response_style"] = "concise"
                elif "è¯¦ç»†" in tag_name:
                    strategy["response_style"] = "detailed"
                elif "å¹½é»˜" in tag_name:
                    strategy["response_tone"] = "humorous"
                elif "æ­£å¼" in tag_name:
                    strategy["response_tone"] = "formal"
        
        return strategy
    
    def _build_response_prompt(self, query: str, knowledge: str, user_tags: Dict, 
                             strategy: Dict, context: Dict = None) -> str:
        """æ„å»ºä¸ªæ€§åŒ–å›åº”prompt"""
        
        # æå–å…³é”®ç”¨æˆ·ç‰¹å¾
        profile_summary = self._extract_profile_summary(user_tags)
        
        # æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯
        context_info = ""
        if context and context.get("conversation_history"):
            recent_messages = context["conversation_history"][-3:]  # æœ€è¿‘3æ¡æ¶ˆæ¯
            context_info = f"æœ€è¿‘å¯¹è¯:\n" + "\n".join([f"- {msg}" for msg in recent_messages]) + "\n\n"
        
        # æ„å»ºå†…å®¹è¿‡æ»¤æŒ‡ä»¤
        filter_instructions = ""
        if strategy.get("content_filters"):
            filter_instructions = f"æ³¨æ„é¿å…æåŠ: {', '.join(strategy['content_filters'])}\n"
        
        # æ„å»ºè¯é¢˜å¼•å¯¼æŒ‡ä»¤
        topic_guidance = ""
        if strategy.get("boost_topics"):
            topic_guidance = f"å¯ä»¥é€‚å½“å¼•å…¥ç”¨æˆ·æ„Ÿå…´è¶£çš„è¯é¢˜: {', '.join(strategy['boost_topics'])}\n"
        
        prompt = f"""
        ä½ æ˜¯ä¸€ä¸ªæ¸©æš–çš„æƒ…æ„Ÿé™ªä¼´åŠ©æ‰‹ï¼Œè¯·åŸºäºä»¥ä¸‹ä¿¡æ¯ç”Ÿæˆä¸ªæ€§åŒ–å›åº”ã€‚
        
        {context_info}ç”¨æˆ·é—®é¢˜: "{query}"
        
        ç›¸å…³çŸ¥è¯†:
        {knowledge}
        
        ç”¨æˆ·ç‰¹å¾:
        {profile_summary}
        
        å›åº”è¦æ±‚:
        - è¯­æ°”é£æ ¼: {strategy.get('response_tone', 'warm')}
        - å›åº”é£æ ¼: {strategy.get('response_style', 'balanced')}
        - æƒ…æ„Ÿé€‚é…: {strategy.get('emotional_adaptation', 'neutral')}
        {filter_instructions}{topic_guidance}
        
        è¯·ç”Ÿæˆä¸€ä¸ª200å­—ä»¥å†…çš„ä¸ªæ€§åŒ–å›åº”ï¼Œè¦ä½“ç°å‡ºå¯¹ç”¨æˆ·ç‰¹å¾çš„ç†è§£å’Œå…³æ€€ã€‚
        """
        
        return prompt
    
    def _extract_profile_summary(self, user_tags: Dict) -> str:
        """æå–ç”¨æˆ·ç”»åƒæ‘˜è¦"""
        dimensions = user_tags.get("tag_dimensions", {})
        summary_parts = []
        
        for dim_key, dim_data in dimensions.items():
            if dim_data.get("dimension_weight", 0) > 0.3:
                dim_name = dim_data.get("dimension_name", dim_key)
                dominant_tag = dim_data.get("dominant_tag")
                weight = dim_data.get("dimension_weight", 0)
                
                if dominant_tag:
                    summary_parts.append(f"- {dim_name}: {dominant_tag} (æƒé‡: {weight:.2f})")
        
        if summary_parts:
            return "\n".join(summary_parts)
        else:
            return "- ç”¨æˆ·ç”»åƒè¿˜åœ¨å»ºç«‹ä¸­ï¼Œé‡‡ç”¨é€šç”¨æ¸©å’Œçš„å›åº”æ–¹å¼"
    
    def _post_process_response(self, response: str, strategy: Dict) -> str:
        """åå¤„ç†å›åº”å†…å®¹"""
        # ç§»é™¤å¯èƒ½çš„æœ‰å®³å†…å®¹
        avoid_topics = strategy.get("avoid_topics", [])
        for topic in avoid_topics:
            if topic in response:
                # è¿™é‡Œå¯ä»¥å®ç°æ›´å¤æ‚çš„å†…å®¹æ›¿æ¢é€»è¾‘
                response = response.replace(topic, "[ç›¸å…³è¯é¢˜]")
        
        # æ ¹æ®é£æ ¼è°ƒæ•´é•¿åº¦
        if strategy.get("response_style") == "concise":
            # å¦‚æœè¦æ±‚ç®€æ´ï¼Œæˆªå–å‰100å­—
            if len(response) > 100:
                response = response[:97] + "..."
        
        return response.strip()
    
    def _get_profile_snapshot(self, user_tags: Dict) -> Dict:
        """è·å–ç”¨æˆ·ç”»åƒå¿«ç…§"""
        metrics = user_tags.get("computed_metrics", {})
        dimensions = user_tags.get("tag_dimensions", {})
        
        snapshot = {
            "emotional_health_index": metrics.get("emotional_health_index", 0.5),
            "profile_maturity": metrics.get("overall_profile_maturity", 0.0),
            "active_dimensions": []
        }
        
        for dim_key, dim_data in dimensions.items():
            if dim_data.get("dimension_weight", 0) > 0.1:
                snapshot["active_dimensions"].append({
                    "dimension": dim_data.get("dimension_name", dim_key),
                    "dominant_tag": dim_data.get("dominant_tag"),
                    "weight": dim_data.get("dimension_weight", 0)
                })
        
        return snapshot
```

### 5. Webç•Œé¢å’ŒAPI (web/app.py)

```python
from flask import Flask, render_template, request, jsonify, session
import uuid
import json
from datetime import datetime
from app.core.lightrag_engine import LightRAGEngine
from app.core.tag_extractor import TagExtractor  
from app.core.tag_manager import TagManager
from app.core.response_generator import ResponseGenerator

app = Flask(__name__)
app.secret_key = 'lightrag_demo_secret_key'

@app.route('/')
def index():
    """ä¸»é¡µ"""
    return render_template('index.html')

@app.route('/api/chat', methods=['POST'])
def chat():
    """èŠå¤©æ¥å£"""
    try:
        data = request.json
        user_message = data.get('message', '')
        
        # è·å–æˆ–åˆ›å»ºç”¨æˆ·ID
        if 'user_id' not in session:
            session['user_id'] = str(uuid.uuid4())
        
        user_id = session['user_id']
        
        # åˆå§‹åŒ–ç»„ä»¶
        tag_extractor = TagExtractor(user_id)
        tag_manager = TagManager(user_id)
        response_generator = ResponseGenerator(user_id)
        
        # æå–æ ‡ç­¾
        extracted_tags = tag_extractor.extract_tags_from_text(user_message)
        
        # æ›´æ–°æ ‡ç­¾
        updated_tags = tag_manager.update_tags(extracted_tags)
        
        # ç”Ÿæˆå›åº”
        response_data = response_generator.generate_response(user_message)
        
        # è®°å½•å¯¹è¯
        conversation_log = {
            "timestamp": datetime.now().isoformat(),
            "user_message": user_message,
            "assistant_response": response_data["response"],
            "extracted_tags": {k: [{"name": tag.name, "confidence": tag.confidence} for tag in v] for k, v in extracted_tags.items()},
            "search_strategy": response_data["search_strategy"]
        }
        
        return jsonify({
            "success": True,
            "response": response_data["response"],
            "user_profile": response_data["user_profile_snapshot"],
            "extracted_tags": {k: [{"name": tag.name, "confidence": tag.confidence} for tag in v] for k, v in extracted_tags.items()},
            "conversation_log": conversation_log
        })
        
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/api/profile')
def get_profile():
    """è·å–ç”¨æˆ·ç”»åƒ"""
    try:
        if 'user_id' not in session:
            return jsonify({"success": False, "error": "ç”¨æˆ·æœªåˆå§‹åŒ–"})
        
        user_id = session['user_id']
        tag_manager = TagManager(user_id)
        user_tags = tag_manager.get_user_tags()
        
        return jsonify({
            "success": True,
            "user_tags": user_tags
        })
        
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/api/add_knowledge', methods=['POST'])
def add_knowledge():
    """æ·»åŠ çŸ¥è¯†"""
    try:
        if 'user_id' not in session:
            return jsonify({"success": False, "error": "ç”¨æˆ·æœªåˆå§‹åŒ–"})
        
        data = request.json
        knowledge_text = data.get('text', '')
        metadata = data.get('metadata', {})
        
        user_id = session['user_id']
        lightrag = LightRAGEngine(user_id)
        
        result = lightrag.insert_knowledge(knowledge_text, metadata)
        
        return jsonify(result)
        
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/api/reset_user', methods=['POST'])
def reset_user():
    """é‡ç½®ç”¨æˆ·ï¼ˆæ–°å»ºç”¨æˆ·ä¼šè¯ï¼‰"""
    session.pop('user_id', None)
    return jsonify({"success": True, "message": "ç”¨æˆ·ä¼šè¯å·²é‡ç½®"})

if __name__ == '__main__':
    app.run(debug=True, port=5000)
```

### 6. HTMLæ¨¡æ¿ (web/templates/index.html)

```html
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LightRAGæ ‡ç­¾ä½“ç³»æ¼”ç¤º</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            margin: 0;
            padding: 0;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            height: 100vh;
        }
        
        .container {
            display: flex;
            height: 100vh;
        }
        
        .chat-section {
            flex: 2;
            background: white;
            margin: 20px;
            border-radius: 10px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            display: flex;
            flex-direction: column;
        }
        
        .profile-section {
            flex: 1;
            background: white;
            margin: 20px 20px 20px 0;
            border-radius: 10px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            padding: 20px;
            overflow-y: auto;
        }
        
        .chat-header {
            background: #4A90E2;
            color: white;
            padding: 15px 20px;
            border-radius: 10px 10px 0 0;
        }
        
        .chat-messages {
            flex: 1;
            padding: 20px;
            overflow-y: auto;
            background: #f8f9fa;
        }
        
        .message {
            margin-bottom: 15px;
            padding: 10px 15px;
            border-radius: 10px;
            max-width: 80%;
        }
        
        .user-message {
            background: #007bff;
            color: white;
            margin-left: auto;
        }
        
        .assistant-message {
            background: white;
            border: 1px solid #e9ecef;
        }
        
        .chat-input {
            display: flex;
            padding: 20px;
            background: white;
            border-radius: 0 0 10px 10px;
            border-top: 1px solid #e9ecef;
        }
        
        .chat-input input {
            flex: 1;
            padding: 10px 15px;
            border: 1px solid #ddd;
            border-radius: 25px;
            outline: none;
        }
        
        .chat-input button {
            margin-left: 10px;
            padding: 10px 20px;
            background: #007bff;
            color: white;
            border: none;
            border-radius: 25px;
            cursor: pointer;
        }
        
        .profile-title {
            color: #4A90E2;
            margin-bottom: 20px;
            padding-bottom: 10px;
            border-bottom: 2px solid #4A90E2;
        }
        
        .dimension-card {
            background: #f8f9fa;
            padding: 15px;
            margin-bottom: 15px;
            border-radius: 8px;
            border-left: 4px solid #007bff;
        }
        
        .tag-item {
            background: #e7f3ff;
            color: #0066cc;
            padding: 5px 10px;
            margin: 5px 5px 5px 0;
            border-radius: 15px;
            display: inline-block;
            font-size: 0.9em;
        }
        
        .metrics-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 10px;
            margin-top: 20px;
        }
        
        .metric-item {
            background: #f0f8ff;
            padding: 10px;
            border-radius: 5px;
            text-align: center;
        }
        
        .loading {
            opacity: 0.7;
            pointer-events: none;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="chat-section">
            <div class="chat-header">
                <h2>ğŸ¤– LightRAGæƒ…æ„Ÿé™ªä¼´åŠ©æ‰‹</h2>
                <p>é›†æˆæ™ºèƒ½æ ‡ç­¾ä½“ç³»çš„ä¸ªæ€§åŒ–èŠå¤©Demo</p>
            </div>
            
            <div class="chat-messages" id="chatMessages">
                <div class="message assistant-message">
                    <strong>åŠ©æ‰‹:</strong> ä½ å¥½ï¼æˆ‘æ˜¯ä½ çš„æƒ…æ„Ÿé™ªä¼´åŠ©æ‰‹ã€‚æˆ‘ä¼šé€šè¿‡æˆ‘ä»¬çš„å¯¹è¯é€æ¸äº†è§£ä½ çš„ç‰¹ç‚¹å’Œåå¥½ï¼Œä¸ºä½ æä¾›æ›´ä¸ªæ€§åŒ–çš„å›åº”ã€‚éšä¾¿èŠäº›ä»€ä¹ˆå§ï¼ ğŸ˜Š
                </div>
            </div>
            
            <div class="chat-input">
                <input type="text" id="messageInput" placeholder="è¾“å…¥ä½ æƒ³è¯´çš„è¯..." 
                       onkeypress="if(event.key==='Enter') sendMessage()">
                <button onclick="sendMessage()">å‘é€</button>
                <button onclick="addKnowledge()" style="background: #28a745;">æ·»åŠ çŸ¥è¯†</button>
                <button onclick="resetUser()" style="background: #dc3545;">é‡ç½®</button>
            </div>
        </div>
        
        <div class="profile-section">
            <h2 class="profile-title">ğŸ‘¤ ç”¨æˆ·ç”»åƒ</h2>
            
            <div id="profileContent">
                <p style="color: #666; text-align: center;">å¼€å§‹å¯¹è¯åï¼Œè¿™é‡Œä¼šæ˜¾ç¤ºä½ çš„ä¸ªæ€§åŒ–æ ‡ç­¾</p>
            </div>
            
            <div id="metricsSection" style="display: none;">
                <h3>ğŸ“Š ç»¼åˆæŒ‡æ ‡</h3>
                <div class="metrics-grid" id="metricsGrid">
                </div>
            </div>
        </div>
    </div>

    <script>
        async function sendMessage() {
            const input = document.getElementById('messageInput');
            const message = input.value.trim();
            
            if (!message) return;
            
            // æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
            addMessageToChat('user', message);
            input.value = '';
            
            // æ˜¾ç¤ºåŠ è½½çŠ¶æ€
            const chatMessages = document.getElementById('chatMessages');
            chatMessages.classList.add('loading');
            
            try {
                const response = await fetch('/api/chat', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({ message: message })
                });
                
                const data = await response.json();
                
                if (data.success) {
                    // æ˜¾ç¤ºåŠ©æ‰‹å›åº”
                    addMessageToChat('assistant', data.response);
                    
                    // æ›´æ–°ç”¨æˆ·ç”»åƒ
                    updateProfile(data.user_profile);
                    
                    // æ˜¾ç¤ºæå–çš„æ ‡ç­¾ï¼ˆç”¨äºè°ƒè¯•ï¼‰
                    if (Object.keys(data.extracted_tags).length > 0) {
                        console.log('æå–çš„æ ‡ç­¾:', data.extracted_tags);
                    }
                } else {
                    addMessageToChat('assistant', 'æŠ±æ­‰ï¼Œå¤„ç†æ¶ˆæ¯æ—¶å‡ºç°é”™è¯¯ï¼š' + data.error);
                }
                
            } catch (error) {
                addMessageToChat('assistant', 'ç½‘ç»œè¿æ¥é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚');
                console.error('Error:', error);
            } finally {
                chatMessages.classList.remove('loading');
            }
        }
        
        function addMessageToChat(sender, message) {
            const chatMessages = document.getElementById('chatMessages');
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${sender}-message`;
            
            if (sender === 'user') {
                messageDiv.innerHTML = `<strong>ä½ :</strong> ${message}`;
            } else {
                messageDiv.innerHTML = `<strong>åŠ©æ‰‹:</strong> ${message}`;
            }
            
            chatMessages.appendChild(messageDiv);
            chatMessages.scrollTop = chatMessages.scrollHeight;
        }
        
        function updateProfile(profileData) {
            const profileContent = document.getElementById('profileContent');
            const metricsSection = document.getElementById('metricsSection');
            const metricsGrid = document.getElementById('metricsGrid');
            
            if (!profileData || profileData.active_dimensions.length === 0) {
                return;
            }
            
            // æ›´æ–°ç»´åº¦ä¿¡æ¯
            let html = '';
            profileData.active_dimensions.forEach(dim => {
                html += `
                    <div class="dimension-card">
                        <h4>${dim.dimension}</h4>
                        <div class="tag-item">${dim.dominant_tag}</div>
                        <div style="margin-top: 10px; font-size: 0.9em; color: #666;">
                            æƒé‡: ${(dim.weight * 100).toFixed(1)}%
                        </div>
                    </div>
                `;
            });
            
            profileContent.innerHTML = html;
            
            // æ›´æ–°æŒ‡æ ‡
            metricsGrid.innerHTML = `
                <div class="metric-item">
                    <div style="font-weight: bold;">æƒ…æ„Ÿå¥åº·</div>
                    <div style="font-size: 1.2em; color: ${profileData.emotional_health_index > 0.6 ? '#28a745' : profileData.emotional_health_index > 0.4 ? '#ffc107' : '#dc3545'};">
                        ${(profileData.emotional_health_index * 100).toFixed(0)}%
                    </div>
                </div>
                <div class="metric-item">
                    <div style="font-weight: bold;">ç”»åƒæˆç†Ÿåº¦</div>
                    <div style="font-size: 1.2em; color: #007bff;">
                        ${(profileData.profile_maturity * 100).toFixed(0)}%
                    </div>
                </div>
            `;
            
            metricsSection.style.display = 'block';
        }
        
        async function addKnowledge() {
            const text = prompt('è¯·è¾“å…¥è¦æ·»åŠ åˆ°çŸ¥è¯†åº“çš„å†…å®¹:');
            if (!text) return;
            
            try {
                const response = await fetch('/api/add_knowledge', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({ text: text })
                });
                
                const data = await response.json();
                
                if (data.status === 'success') {
                    alert('çŸ¥è¯†æ·»åŠ æˆåŠŸï¼');
                } else {
                    alert('æ·»åŠ å¤±è´¥ï¼š' + data.message);
                }
            } catch (error) {
                alert('ç½‘ç»œé”™è¯¯ï¼Œè¯·ç¨åé‡è¯•');
            }
        }
        
        async function resetUser() {
            if (!confirm('ç¡®å®šè¦é‡ç½®ç”¨æˆ·ä¼šè¯å—ï¼Ÿè¿™å°†æ¸…é™¤å½“å‰çš„å¯¹è¯å†å²å’Œç”¨æˆ·ç”»åƒã€‚')) {
                return;
            }
            
            try {
                const response = await fetch('/api/reset_user', {
                    method: 'POST'
                });
                
                const data = await response.json();
                
                if (data.success) {
                    // æ¸…ç©ºèŠå¤©è®°å½•
                    document.getElementById('chatMessages').innerHTML = `
                        <div class="message assistant-message">
                            <strong>åŠ©æ‰‹:</strong> ä½ å¥½ï¼æˆ‘æ˜¯ä½ çš„æƒ…æ„Ÿé™ªä¼´åŠ©æ‰‹ã€‚æˆ‘ä¼šé€šè¿‡æˆ‘ä»¬çš„å¯¹è¯é€æ¸äº†è§£ä½ çš„ç‰¹ç‚¹å’Œåå¥½ï¼Œä¸ºä½ æä¾›æ›´ä¸ªæ€§åŒ–çš„å›åº”ã€‚éšä¾¿èŠäº›ä»€ä¹ˆå§ï¼ ğŸ˜Š
                        </div>
                    `;
                    
                    // é‡ç½®ç”¨æˆ·ç”»åƒ
                    document.getElementById('profileContent').innerHTML = `
                        <p style="color: #666; text-align: center;">å¼€å§‹å¯¹è¯åï¼Œè¿™é‡Œä¼šæ˜¾ç¤ºä½ çš„ä¸ªæ€§åŒ–æ ‡ç­¾</p>
                    `;
                    
                    document.getElementById('metricsSection').style.display = 'none';
                    
                    alert('ç”¨æˆ·ä¼šè¯å·²é‡ç½®ï¼');
                } else {
                    alert('é‡ç½®å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•');
                }
            } catch (error) {
                alert('ç½‘ç»œé”™è¯¯ï¼Œè¯·ç¨åé‡è¯•');
            }
        }
        
        // é¡µé¢åŠ è½½æ—¶è·å–ç”¨æˆ·ç”»åƒ
        window.onload = async function() {
            try {
                const response = await fetch('/api/profile');
                const data = await response.json();
                
                if (data.success && data.user_tags.computed_metrics.overall_profile_maturity > 0) {
                    // å¦‚æœç”¨æˆ·å·²æœ‰ç”»åƒæ•°æ®ï¼Œæ˜¾ç¤ºå®ƒ
                    const dimensions = data.user_tags.tag_dimensions;
                    const activeDimensions = [];
                    
                    for (const [key, dim] of Object.entries(dimensions)) {
                        if (dim.dimension_weight > 0.1) {
                            activeDimensions.push({
                                dimension: dim.dimension_name,
                                dominant_tag: dim.dominant_tag,
                                weight: dim.dimension_weight
                            });
                        }
                    }
                    
                    if (activeDimensions.length > 0) {
                        updateProfile({
                            active_dimensions: activeDimensions,
                            emotional_health_index: data.user_tags.computed_metrics.emotional_health_index,
                            profile_maturity: data.user_tags.computed_metrics.overall_profile_maturity
                        });
                    }
                }
            } catch (error) {
                console.log('è·å–ç”¨æˆ·ç”»åƒå¤±è´¥:', error);
            }
        };
    </script>
</body>
</html>
```

### 7. é…ç½®æ–‡ä»¶ (config.yaml)

```yaml
# LightRAGæ ‡ç­¾ç³»ç»Ÿé…ç½®
app:
  name: "LightRAG-TagSystem-Demo"
  version: "1.0.0"
  debug: true

llm:
  provider: "openai"
  model: "gpt-3.5-turbo"
  api_key: "your-openai-api-key-here"
  max_tokens: 500
  temperature: 0.7

embedding:
  provider: "openai"
  model: "text-embedding-ada-002"
  
storage:
  type: "local"
  base_path: "./user_data"
  backup_enabled: true
  cleanup_days: 90

tag_system:
  dimensions:
    emotional_traits: "æƒ…æ„Ÿç‰¹å¾"
    interest_preferences: "å…´è¶£åå¥½"
    interaction_habits: "äº’åŠ¨ä¹ æƒ¯"
    value_principles: "ä»·å€¼è§‚"
  
  extraction:
    max_tags_per_dimension: 5
    confidence_threshold: 0.3
    decay_rate: 0.1
  
  weights:
    time_decay_days: 30
    usage_boost_factor: 1.2
    consistency_weight: 0.8

web:
  host: "127.0.0.1"
  port: 5000
  secret_key: "lightrag_demo_secret_key"
```

### 8. å¯åŠ¨è„šæœ¬ (run_demo.py)

```python
#!/usr/bin/env python3
"""
LightRAGæ ‡ç­¾ä½“ç³»æ¼”ç¤ºDemoå¯åŠ¨è„šæœ¬
"""
import os
import sys
import yaml
from pathlib import Path

def load_config():
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    config_path = Path("config.yaml")
    if not config_path.exists():
        print("é”™è¯¯: é…ç½®æ–‡ä»¶ config.yaml ä¸å­˜åœ¨")
        sys.exit(1)
    
    with open(config_path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)

def setup_environment():
    """è®¾ç½®ç¯å¢ƒå˜é‡"""
    config = load_config()
    
    # è®¾ç½®OpenAI API Key
    api_key = config.get('llm', {}).get('api_key')
    if not api_key or api_key == "your-openai-api-key-here":
        api_key = input("è¯·è¾“å…¥ä½ çš„OpenAI API Key: ").strip()
        if not api_key:
            print("é”™è¯¯: éœ€è¦OpenAI API Keyæ‰èƒ½è¿è¡ŒDemo")
            sys.exit(1)
    
    os.environ['OPENAI_API_KEY'] = api_key
    
    return config

def create_directories():
    """åˆ›å»ºå¿…è¦çš„ç›®å½•"""
    directories = [
        "user_data",
        "user_data/global", 
        "logs"
    ]
    
    for directory in directories:
        Path(directory).mkdir(parents=True, exist_ok=True)
    
    print("âœ… ç›®å½•ç»“æ„åˆ›å»ºå®Œæˆ")

def check_dependencies():
    """æ£€æŸ¥ä¾èµ–åŒ…"""
    required_packages = [
        "lightrag", "openai", "flask", "pydantic", "chromadb"
    ]
    
    missing_packages = []
    for package in required_packages:
        try:
            __import__(package)
        except ImportError:
            missing_packages.append(package)
    
    if missing_packages:
        print(f"é”™è¯¯: ç¼ºå°‘ä¾èµ–åŒ…: {', '.join(missing_packages)}")
        print("è¯·è¿è¡Œ: pip install -r requirements.txt")
        sys.exit(1)
    
    print("âœ… ä¾èµ–åŒ…æ£€æŸ¥é€šè¿‡")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨ LightRAGæ ‡ç­¾ä½“ç³»æ¼”ç¤ºDemo...")
    
    # æ£€æŸ¥ä¾èµ–
    check_dependencies()
    
    # è®¾ç½®ç¯å¢ƒ
    config = setup_environment()
    
    # åˆ›å»ºç›®å½•
    create_directories()
    
    # å¯åŠ¨Webåº”ç”¨
    try:
        from web.app import app
        
        host = config.get('web', {}).get('host', '127.0.0.1')
        port = config.get('web', {}).get('port', 5000)
        debug = config.get('app', {}).get('debug', True)
        
        print(f"âœ… Demoå¯åŠ¨æˆåŠŸ!")
        print(f"ğŸ“± è®¿é—®åœ°å€: http://{host}:{port}")
        print("ğŸ’¡ ä½¿ç”¨è¯´æ˜:")
        print("   1. åœ¨èŠå¤©ç•Œé¢ä¸åŠ©æ‰‹å¯¹è¯")
        print("   2. è§‚å¯Ÿå³ä¾§ç”¨æˆ·ç”»åƒçš„å®æ—¶æ›´æ–°")
        print("   3. å¯ä»¥æ·»åŠ çŸ¥è¯†åˆ°ä¸ªäººçŸ¥è¯†åº“")
        print("   4. é‡ç½®æŒ‰é’®å¯ä»¥æ¸…é™¤ä¼šè¯æ•°æ®")
        print("\nğŸ¯ å¼€å§‹ä½“éªŒä¸ªæ€§åŒ–çš„æƒ…æ„Ÿé™ªä¼´å§!")
        
        app.run(host=host, port=port, debug=debug)
        
    except Exception as e:
        print(f"âŒ å¯åŠ¨å¤±è´¥: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
```

---

## ğŸš€ éƒ¨ç½²è¿è¡Œæ­¥éª¤

### 1. ç¯å¢ƒå‡†å¤‡
```bash
# å…‹éš†æˆ–åˆ›å»ºé¡¹ç›®ç›®å½•
mkdir LightRAG-TagSystem-Demo
cd LightRAG-TagSystem-Demo

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### 2. é…ç½®è®¾ç½®
```bash
# ç¼–è¾‘ config.yamlï¼Œå¡«å…¥ä½ çš„ OpenAI API Key
# æˆ–è€…åœ¨å¯åŠ¨æ—¶ä¼šæç¤ºè¾“å…¥
```

### 3. å¯åŠ¨Demo
```bash
python run_demo.py
```

### 4. è®¿é—®æµ‹è¯•
```bash
# æ‰“å¼€æµè§ˆå™¨è®¿é—®
http://127.0.0.1:5000
```

---

## ğŸ¯ DemoåŠŸèƒ½ç‰¹æ€§

### æ ¸å¿ƒåŠŸèƒ½æ¼”ç¤º
1. **å®æ—¶æ ‡ç­¾æå–**: æ¯æ¬¡å¯¹è¯è‡ªåŠ¨æå–ç”¨æˆ·ç‰¹å¾æ ‡ç­¾
2. **åŠ¨æ€æƒé‡æ›´æ–°**: æ ‡ç­¾æƒé‡æ ¹æ®ä½¿ç”¨é¢‘ç‡å’Œæ—¶é—´è¡°å‡
3. **ä¸ªæ€§åŒ–å›åº”**: åŸºäºç”¨æˆ·ç”»åƒè°ƒæ•´å›åº”é£æ ¼å’Œå†…å®¹
4. **çŸ¥è¯†åº“ç®¡ç†**: æ”¯æŒæ·»åŠ ä¸ªäººçŸ¥è¯†åˆ°LightRAG
5. **ç”¨æˆ·ç”»åƒå¯è§†åŒ–**: å®æ—¶æ˜¾ç¤ºæ ‡ç­¾ç»´åº¦å’Œç»¼åˆæŒ‡æ ‡

### æŠ€æœ¯ç‰¹è‰²
- **è½»é‡åŒ–æ¶æ„**: ä½¿ç”¨æœ¬åœ°JSONæ–‡ä»¶å­˜å‚¨ï¼Œæ— éœ€æ•°æ®åº“
- **ç”¨æˆ·éš”ç¦»**: æ¯ç”¨æˆ·ç‹¬ç«‹çš„æ–‡ä»¶å¤¹å’Œæ ‡ç­¾ä½“ç³»
- **æ¨¡å—åŒ–è®¾è®¡**: æ ¸å¿ƒç»„ä»¶å¯ç‹¬ç«‹ä½¿ç”¨å’Œæ‰©å±•
- **å“åº”å¼ç•Œé¢**: ç°ä»£åŒ–çš„Webç•Œé¢ï¼Œå®æ—¶æ›´æ–°

è¿™å¥—Demoå®Œæ•´å®ç°äº†æˆ‘ä»¬è®¨è®ºçš„æ ‡ç­¾ä½“ç³»è®¾è®¡ï¼Œå¯ä»¥ç›´æ¥éƒ¨ç½²ä½“éªŒLightRAG+æ ‡ç­¾ç³»ç»Ÿçš„å¼ºå¤§åŠŸèƒ½ï¼
