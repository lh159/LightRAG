import sys
import os
from datetime import datetime
from typing import Dict, List

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ä»¥ä¾¿å¯¼å…¥
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from core.lightrag_engine import LightRAGEngine
from core.tag_manager import TagManager
from utils.llm_client import LLMClient

class ResponseGenerator:
    def __init__(self, user_id: str):
        self.user_id = user_id
        self.lightrag = LightRAGEngine(user_id)
        self.tag_manager = TagManager(user_id)
        self.llm_client = LLMClient()
        
    def generate_response(self, user_query: str, context: Dict = None) -> Dict:
        """ç”Ÿæˆä¸ªæ€§åŒ–å›åº”"""
        
        # 1. è·å–ç”¨æˆ·æ ‡ç­¾
        user_tags = self.tag_manager.get_user_tags()
        
        # 2. åŸºäºæ ‡ç­¾ç”Ÿæˆæ£€ç´¢ç­–ç•¥
        search_strategy = self._generate_search_strategy(user_tags, user_query)
        
        # 3. ä½¿ç”¨LightRAGæ£€ç´¢ç›¸å…³çŸ¥è¯†
        relevant_knowledge = self.lightrag.query_knowledge(
            user_query, 
            mode=search_strategy.get("search_mode", "hybrid")
        )
        
        # 4. æ„å»ºä¸ªæ€§åŒ–å›åº”prompt
        personalized_prompt = self._build_response_prompt(
            user_query, 
            relevant_knowledge, 
            user_tags, 
            search_strategy,
            context
        )
        
        # 5. ç”Ÿæˆå›åº” (ä½¿ç”¨LightRAGå¼•æ“)
        response = self.lightrag.generate_response(
            personalized_prompt,
            max_tokens=500
        )
        
        # 6. åå¤„ç†å’Œå®‰å…¨æ£€æŸ¥
        final_response = self._post_process_response(response, search_strategy)
        
        return {
            "response": final_response,
            "search_strategy": search_strategy,
            "knowledge_used": relevant_knowledge[:200] + "..." if len(relevant_knowledge) > 200 else relevant_knowledge,
            "user_profile_snapshot": self._get_profile_snapshot(user_tags)
        }
    
    def _generate_search_strategy(self, user_tags: Dict, query: str) -> Dict:
        """åŸºäºç”¨æˆ·æ ‡ç­¾ç”Ÿæˆæ£€ç´¢ç­–ç•¥"""
        strategy = {
            "search_mode": "hybrid",
            "response_tone": "warm",
            "response_style": "balanced",
            "content_filters": [],
            "boost_topics": [],
            "avoid_topics": [],
            "emotional_adaptation": "neutral"
        }
        
        dimensions = user_tags.get("tag_dimensions", {})
        
        # åŸºäºæƒ…æ„Ÿç‰¹å¾è°ƒæ•´
        emotional_dim = dimensions.get("emotional_traits", {})
        if emotional_dim.get("dimension_weight", 0) > 0.5:
            dominant_emotional = emotional_dim.get("dominant_tag", "")
            
            if "æ•æ„Ÿ" in dominant_emotional or "ç„¦è™‘" in dominant_emotional:
                strategy["response_tone"] = "gentle"
                strategy["content_filters"].extend(["æ‰¹è¯„", "å¦å®š", "å¤±è´¥"])
                strategy["emotional_adaptation"] = "supportive"
            elif "ä¹è§‚" in dominant_emotional or "ç§¯æ" in dominant_emotional:
                strategy["response_tone"] = "upbeat"
                strategy["emotional_adaptation"] = "encouraging"
        
        return strategy
    
    def _build_response_prompt(self, query: str, knowledge: str, user_tags: Dict, 
                             strategy: Dict, context: Dict = None) -> str:
        """æ„å»ºä¸ªæ€§åŒ–å›åº”prompt"""
        
        # æå–å…³é”®ç”¨æˆ·ç‰¹å¾
        profile_summary = self._extract_profile_summary(user_tags)
        
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ¸©æš–çš„æƒ…æ„Ÿé™ªä¼´åŠ©æ‰‹ï¼Œè¯·åŸºäºä»¥ä¸‹ä¿¡æ¯ç”Ÿæˆä¸ªæ€§åŒ–å›åº”ã€‚

ç”¨æˆ·é—®é¢˜: "{query}"

ç›¸å…³çŸ¥è¯†:
{knowledge}

ç”¨æˆ·ç‰¹å¾:
{profile_summary}

å›åº”è¦æ±‚:
- è¯­æ°”é£æ ¼: {strategy.get('response_tone', 'warm')}
- å›åº”é£æ ¼: {strategy.get('response_style', 'balanced')}  
- æƒ…æ„Ÿé€‚é…: {strategy.get('emotional_adaptation', 'neutral')}

è¯·ç”Ÿæˆä¸€ä¸ª200å­—ä»¥å†…çš„ä¸ªæ€§åŒ–å›åº”ï¼Œè¦ä½“ç°å‡ºå¯¹ç”¨æˆ·ç‰¹å¾çš„ç†è§£å’Œå…³æ€€ã€‚ä½¿ç”¨ä¸­æ–‡å›å¤ã€‚"""
        
        return prompt
    
    def _extract_profile_summary(self, user_tags: Dict) -> str:
        """æå–ç”¨æˆ·ç”»åƒæ‘˜è¦"""
        dimensions = user_tags.get("tag_dimensions", {})
        summary_parts = []
        
        for dim_key, dim_data in dimensions.items():
            if dim_data.get("dimension_weight", 0) > 0.3:
                dim_name = dim_data.get("dimension_name", dim_key)
                active_tags = dim_data.get("active_tags", [])
                
                if active_tags:
                    # æ˜¾ç¤ºå‰3ä¸ªæœ€é‡è¦çš„æ ‡ç­¾
                    top_tags = sorted(active_tags, key=lambda x: x.get("current_weight", 0), reverse=True)[:3]
                    tag_names = [tag["tag_name"] for tag in top_tags]
                    summary_parts.append(f"- {dim_name}: {', '.join(tag_names)}")
        
        if summary_parts:
            return "\n".join(summary_parts)
        else:
            return "- ç”¨æˆ·ç”»åƒè¿˜åœ¨å»ºç«‹ä¸­ï¼Œé‡‡ç”¨é€šç”¨æ¸©å’Œçš„å›åº”æ–¹å¼"
    
    def _post_process_response(self, response: str, strategy: Dict) -> str:
        """åå¤„ç†å›åº”å†…å®¹"""
        if not response:
            return "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•ç”Ÿæˆå›åº”ï¼Œè¯·ç¨åé‡è¯•ã€‚"
            
        # æ ¹æ®é£æ ¼è°ƒæ•´é•¿åº¦
        if strategy.get("response_style") == "concise":
            # å¦‚æœè¦æ±‚ç®€æ´ï¼Œæˆªå–å‰100å­—
            if len(response) > 100:
                response = response[:97] + "..."
        
        return response.strip()
    
    def _get_profile_snapshot(self, user_tags: Dict) -> Dict:
        """è·å–ç”¨æˆ·ç”»åƒå¿«ç…§ - å¢å¼ºç‰ˆï¼ŒåŒ…å«å†²çªå¤„ç†ä¿¡æ¯"""
        metrics = user_tags.get("computed_metrics", {})
        dimensions = user_tags.get("tag_dimensions", {})
        
        snapshot = {
            "emotional_health_index": metrics.get("emotional_health_index", 0.5),
            "profile_maturity": metrics.get("overall_profile_maturity", 0.0),
            "active_dimensions": [],
            "global_conflict_summary": self._get_global_conflict_summary(user_tags)
        }
        
        for dim_key, dim_data in dimensions.items():
            if dim_data.get("dimension_weight", 0) > 0.1:
                active_tags = dim_data.get("active_tags", [])
                
                # è·å–è¯¥ç»´åº¦çš„å‰8ä¸ªæœ€é‡è¦æ ‡ç­¾ï¼ˆå¢åŠ æ•°é‡ï¼‰
                sorted_tags = sorted(active_tags, key=lambda x: x.get("current_weight", 0), reverse=True)[:8]
                
                # ğŸ†• åˆ†ç±»æ ‡ç­¾ï¼šå½“å‰æ ‡ç­¾ã€å†å²æ ‡ç­¾ã€ä¸Šä¸‹æ–‡æ ‡ç­¾
                current_tags = []
                historical_tags = []
                contextual_tags = []
                
                for tag in sorted_tags:
                    tag_info = {
                        "name": tag["tag_name"],
                        "weight": tag.get("current_weight", 0),
                        "confidence": tag.get("avg_confidence", 0),
                        "evidence_count": tag.get("evidence_count", 0),
                        "first_detected": tag.get("first_detected", ""),
                        "last_reinforced": tag.get("last_reinforced", ""),
                        "evidence": tag.get("evidence", "")[:100] + "..." if len(tag.get("evidence", "")) > 100 else tag.get("evidence", ""),
                        "is_historical": tag.get("is_historical", False),
                        "is_contextual": tag.get("is_contextual", False),
                        "conflict_resolved": tag.get("conflict_resolved", False)
                    }
                    
                    if tag.get("is_historical", False):
                        historical_tags.append(tag_info)
                    elif tag.get("is_contextual", False):
                        contextual_tags.append(tag_info)
                    else:
                        current_tags.append(tag_info)
                
                # ğŸ†• è·å–æœ€è¿‘çš„å†²çªå†å²
                recent_conflicts = dim_data.get("conflict_history", [])[-3:]
                
                # ğŸ†• è®¡ç®—æ ‡ç­¾å˜åŒ–è¶‹åŠ¿
                tag_trend = self._calculate_tag_trend(active_tags)
                
                snapshot["active_dimensions"].append({
                    "dimension": dim_data.get("dimension_name", dim_key),
                    "dimension_key": dim_key,
                    "dominant_tag": dim_data.get("dominant_tag"),
                    "dimension_weight": dim_data.get("dimension_weight", 0),
                    "stability_score": dim_data.get("stability_score", 0),
                    
                    # ğŸ†• å¢å¼ºçš„æ ‡ç­¾åˆ†ç±»
                    "current_tags": current_tags,
                    "historical_tags": historical_tags,
                    "contextual_tags": contextual_tags,
                    
                    # ğŸ†• å†²çªå’Œå˜åŒ–ä¿¡æ¯
                    "recent_conflicts": recent_conflicts,
                    "tag_trend": tag_trend,
                    "total_tags": len(active_tags),
                    "conflict_count": len(dim_data.get("conflict_history", [])),
                    
                    # å…¼å®¹æ€§ï¼šä¿ç•™åŸæœ‰çš„tagså­—æ®µ
                    "tags": current_tags + contextual_tags
                })
        
        return snapshot
    
    def _get_global_conflict_summary(self, user_tags: Dict) -> Dict:
        """è·å–å…¨å±€å†²çªæ‘˜è¦"""
        all_conflicts = []
        
        # æ”¶é›†æ‰€æœ‰ç»´åº¦çš„å†²çª
        for dim_data in user_tags.get("tag_dimensions", {}).values():
            all_conflicts.extend(dim_data.get("conflict_history", []))
        
        # æŒ‰æ—¶é—´æ’åºï¼Œè·å–æœ€è¿‘çš„å†²çª
        all_conflicts.sort(key=lambda x: x.get("timestamp", ""), reverse=True)
        recent_conflicts = all_conflicts[:5]
        
        # ç»Ÿè®¡å†²çªç±»å‹
        conflict_types = {}
        for conflict in all_conflicts:
            conflict_type = conflict.get("conflict_type", "unknown")
            conflict_types[conflict_type] = conflict_types.get(conflict_type, 0) + 1
        
        return {
            "total_conflicts": len(all_conflicts),
            "recent_conflicts": recent_conflicts,
            "conflict_type_stats": conflict_types,
            "last_conflict_time": recent_conflicts[0].get("timestamp", "") if recent_conflicts else ""
        }
    
    def _calculate_tag_trend(self, active_tags: List[Dict]) -> Dict:
        """è®¡ç®—æ ‡ç­¾å˜åŒ–è¶‹åŠ¿"""
        if not active_tags:
            return {"trend": "stable", "description": "æš‚æ— æ•°æ®"}
        
        # è®¡ç®—æœ€è¿‘å¼ºåŒ–çš„æ ‡ç­¾æ•°é‡
        now = datetime.now()
        recent_reinforced = 0
        
        for tag in active_tags:
            try:
                last_reinforced = datetime.fromisoformat(tag.get("last_reinforced", ""))
                days_since = (now - last_reinforced).days
                if days_since <= 7:  # ä¸€å‘¨å†…å¼ºåŒ–çš„æ ‡ç­¾
                    recent_reinforced += 1
            except:
                continue
        
        total_tags = len(active_tags)
        recent_ratio = recent_reinforced / total_tags if total_tags > 0 else 0
        
        if recent_ratio > 0.5:
            return {"trend": "active", "description": f"è¿‘æœŸæ´»è·ƒï¼Œ{recent_reinforced}/{total_tags}ä¸ªæ ‡ç­¾è¢«å¼ºåŒ–"}
        elif recent_ratio > 0.2:
            return {"trend": "moderate", "description": f"é€‚åº¦å˜åŒ–ï¼Œ{recent_reinforced}/{total_tags}ä¸ªæ ‡ç­¾è¢«å¼ºåŒ–"}
        else:
            return {"trend": "stable", "description": f"ç›¸å¯¹ç¨³å®šï¼Œ{recent_reinforced}/{total_tags}ä¸ªæ ‡ç­¾è¢«å¼ºåŒ–"}
